from __future__ import print_function
import numpy as np
import os,sys,time

try:
    disable_mpi_env = os.environ['DISABLE_MPI']
    disable_mpi = True if disable_mpi_env.lower().strip() == "true" else False
except:
    disable_mpi = False


# From Sigurd's enlib.mpi:
# Uncaught exceptions don't cause mpi to abort. This can lead to thousands of
# wasted CPU hours
def cleanup(type, value, traceback):
	sys.__excepthook__(type, value, traceback)
	MPI.COMM_WORLD.Abort(1)
sys.excepthook = cleanup

class fakeMpiComm:
    """
    A Simple Fake MPI implementation
    """
    def __init__(self):
        pass
    def Get_rank(self):
        return 0
    def Get_size(self):
        return 1
    def Barrier(self):
        pass
    def Abort(self,dummy):
        pass




try:
    if disable_mpi: raise
    from mpi4py import MPI
except:

    class template:
        pass

    MPI = template()
    MPI.COMM_WORLD = fakeMpiComm()


def mpi_distribute(num_tasks,avail_cores):

    assert avail_cores<=num_tasks
    min_each, rem = divmod(num_tasks,avail_cores)
    num_each = np.array([min_each]*avail_cores) # first distribute equally
    if rem>0: num_each[-rem:] += 1  # add the remainder to the last set of cores (so that rank 0 never gets extra jobs)

    task_range = list(range(num_tasks)) # the full range of tasks
    cumul = np.cumsum(num_each).tolist() # the end indices for each task
    task_dist = [task_range[x:y] for x,y in zip([0]+cumul[:-1],cumul)] # a list containing the tasks for each core
    return num_each,task_dist
    

class Grid(object):

    def __init__(self,comm,shape):

        self.comm = comm
        self.mine = np.zeros(shape)

    

        

### SCINET JOBMAKER
"""
Not technically MPI and kind of legacy.
"""

class jobMaker:

    '''
    Use this to send jobs to SciNet GPC in batches of numCores
    '''
    

    def __init__(self,projectName,walltime,commandPreFix="",numCores=8,queue='debug',jobRoot=None):
        

        self.numCores = numCores
        self.queue = queue
        self._headerText = "#!/bin/bash\n"+\
            "# MOAB/Torque submission script for multiple serial jobs on\n"+\
            "# SciNet GPC automatically generated by gpcInterface.jobMaker().\n"+\
            "#\n"+\
            "#PBS -l nodes=1:ppn=8,walltime="
        self._headerText2 = "\n#PBS -N "
        self._headerText3 = "\n#PBS -q " 
        self._headerText4 = "\n# DIRECTORY TO RUN - $PBS_O_WORKDIR is directory job was submitted from\n"+\
            "cd $PBS_O_WORKDIR\n"
        
        self.name = projectName
        self.walltime = walltime

        self._header = self._headerText + self.walltime + self._headerText2 + self.name + self._headerText3 + self.queue + self._headerText4

        self.jobScript = self._header

        if commandPreFix!="":
            self.prefix = commandPreFix+"; "
        else:
            self.prefix = commandPreFix

        self.scripts = []
        self._jobCount = 0
        self.submittedJobIDs = []

        if jobRoot==None:
            self._jobRoot = "jobs/"
        else:
            self._jobRoot = jobRoot
        self._jobLog = open(jobRoot+"jobs.log",'a')
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
        self._jobLog.write("\nStarted jobMaker object named =="+self.name+"== at "+timestamp)

    def addJob(self,command):

        self._jobCount+=1
        self.jobScript = self.jobScript+"\n("+self.prefix+command+") &"

        if self._jobCount%self.numCores==0:
            self.scripts.append(self.jobScript + "\n\nwait\n")
            self.jobScript = self._header

    def submit(self):
        import re

        if self._jobCount%self.numCores!=0:
            self.scripts.append(self.jobScript + "\n\nwait\n")
            self.jobScript = self._header

        self.jobScript = self._header

        j=0
        for script in self.scripts:
            j+=1
            filename = self._jobRoot+self.name+str(time.time())+str(j)+".sh"
            with open(filename,'w') as tempFile:
                tempFile.write(script)

            # print script
            # continue
            #sys.exit()    
            ##suboutput = os.popen('python labs/testthis.py').read()
            suboutput = os.popen('qsub '+filename).read()
            print (suboutput)
            jobid = int(re.findall('\d+', suboutput)[0])
            self.submittedJobIDs.append(jobid)

            timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
            self._jobLog.write("\nOutput from script submitted at  "+timestamp+":\n"+suboutput)

            


        print (self._jobCount, "job(s) submitted in", j, "script(s).")
        
        self.scripts = []
        self._jobCount = 0



    
    def __del__(self):
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
        self._jobLog.write("\nClosed jobMaker object named =="+self.name+"== at "+timestamp)
        self._jobLog.close()
